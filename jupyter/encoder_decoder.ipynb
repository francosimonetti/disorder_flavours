{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e74dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.patches import Patch\n",
    "import mpl_stylesheet\n",
    "import re\n",
    "import gc\n",
    "mpl_stylesheet.banskt_presentation(fontfamily = 'mono', fontsize = 20, colors = 'banskt', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b90f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel, T5Model, T5ForConditionalGeneration\n",
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "## Download models from: \n",
    "## https://github.com/sacdallago/bio_embeddings/blob/develop/bio_embeddings/utilities/defaults.yml\n",
    "\n",
    "# prottrans_t5_bfd:\n",
    "#   model_directory: \"http://data.bioembeddings.com/public/embeddings/embedding_models/t5/prottrans_t5_bfd.zip\"\n",
    "# prottrans_t5_uniref50:\n",
    "#   model_directory: \"http://data.bioembeddings.com/public/embeddings/embedding_models/t5/prottrans_t5_uniref50.zip\"\n",
    "# prottrans_t5_xl_u50:\n",
    "#   model_directory: \"http://data.bioembeddings.com/public/embeddings/embedding_models/t5/prottrans_t5_xl_u50.zip\"\n",
    "#   half_precision_model_directory: \"http://data.bioembeddings.com/public/embeddings/embedding_models/t5/half_prottrans_t5_xl_u50.zip\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430a0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullmodel = T5ForConditionalGenerationodelnditionalGeneration.from_pretrained(\"/data/franco/datasets/prot_embedding_weights/prottrans_t5_xl_u50/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92b86763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data/franco/datasets/prot_embedding_weights/prottrans_t5_xl_u50/ were not used when initializing T5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "fullmodel_nohead = T5Model.from_pretrained(\"/data/franco/datasets/prot_embedding_weights/prottrans_t5_xl_u50/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1bea60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('/data/franco/datasets/prot_embedding_weights/prottrans_t5_xl_u50', do_lower_case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daadccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "#model = T5EncoderModel.from_pretrained(\"models/half_prottrans_t5_xl_u50\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b543acb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef5f6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only GPUs support half-precision currently; if you want to run on CPU use full-precision (not recommended, much slower)\n",
    "#fullmodel.full() if device=='cpu' else fullmodel.half()\n",
    "#gc.collect()\n",
    "\n",
    "# prepare your protein sequences as a list\n",
    "sequence_examples = [\"PRTEINO\", \"SEQWENCE\"]\n",
    "\n",
    "# replace all rare/ambiguous amino acids by X and introduce white-space between all amino acids\n",
    "sequence_examples = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in sequence_examples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46aa5a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P R T E I N X', 'S E Q W E N C E']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec43ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# tokenize sequences and pad up to the longest sequence in the batch\n",
    "ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding=\"longest\")\n",
    "\n",
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "\n",
    "# generate embeddings\n",
    "with torch.no_grad():\n",
    "    embedding_repr = fullmodel(input_ids=input_ids,attention_mask=attention_mask, decoder_input_ids=input_ids)\n",
    "\n",
    "## A better way to obtain the 'correct' embedding length\n",
    "# features = [] \n",
    "# for seq_num in range(len(embedding)):\n",
    "#     seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "#     seq_emd = embedding[seq_num][:seq_len-1]\n",
    "#     features.append(seq_emd)\n",
    "    \n",
    "# # extract residue embeddings for the first ([0,:]) sequence in the batch and remove padded & special tokens ([0,:7]) \n",
    "# emb_0 = embedding_repr.last_hidden_state[0,:7] # shape (7 x 1024)\n",
    "# # same for the second ([1,:]) sequence but taking into account different sequence lengths ([1,:8])\n",
    "# emb_1 = embedding_repr.last_hidden_state[1,:8] # shape (8 x 1024)\n",
    "\n",
    "# # if you want to derive a single representation (per-protein embedding) for the whole protein\n",
    "# emb_0_per_protein = emb_0.mean(dim=0) # shape (1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29167bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(embedding_repr.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "67b8b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P R X T E I N A']\n",
      "['P <extra_id_0> X T E I N A']\n",
      "{'input_ids': [[13, 8, 23, 11, 9, 12, 17, 3, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[13, 127, 23, 11, 9, 12, 17, 3, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "testsequence = \"PROTEINA\"\n",
    "input_test = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", testsequence)))]\n",
    "print(input_test)\n",
    "\n",
    "ix2replace = int(random.random()*len(testsequence))\n",
    "tmp =  input_test[0].split()\n",
    "tmp[ix2replace] = \"<extra_id_0>\"\n",
    "new_input_test = [\" \".join(tmp)]\n",
    "print(new_input_test)\n",
    "\n",
    "ids1 = tokenizer.batch_encode_plus(input_test, add_special_tokens=True, padding=\"longest\")\n",
    "print(ids1)\n",
    "ids2 = tokenizer.batch_encode_plus(new_input_test, add_special_tokens=True, padding=\"longest\")\n",
    "print(ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e37193b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [13, 8, 127, 11, 9, 12, 17, 3, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"P R <extra_id_0> T E I N A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8d70ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '</s>': 1,\n",
       " '<unk>': 2,\n",
       " '▁A': 3,\n",
       " '▁L': 4,\n",
       " '▁G': 5,\n",
       " '▁V': 6,\n",
       " '▁S': 7,\n",
       " '▁R': 8,\n",
       " '▁E': 9,\n",
       " '▁D': 10,\n",
       " '▁T': 11,\n",
       " '▁I': 12,\n",
       " '▁P': 13,\n",
       " '▁K': 14,\n",
       " '▁F': 15,\n",
       " '▁Q': 16,\n",
       " '▁N': 17,\n",
       " '▁Y': 18,\n",
       " '▁M': 19,\n",
       " '▁H': 20,\n",
       " '▁W': 21,\n",
       " '▁C': 22,\n",
       " '▁X': 23,\n",
       " '▁B': 24,\n",
       " '▁O': 25,\n",
       " '▁U': 26,\n",
       " '▁Z': 27,\n",
       " '<extra_id_99>': 28,\n",
       " '<extra_id_98>': 29,\n",
       " '<extra_id_97>': 30,\n",
       " '<extra_id_96>': 31,\n",
       " '<extra_id_95>': 32,\n",
       " '<extra_id_94>': 33,\n",
       " '<extra_id_93>': 34,\n",
       " '<extra_id_92>': 35,\n",
       " '<extra_id_91>': 36,\n",
       " '<extra_id_90>': 37,\n",
       " '<extra_id_89>': 38,\n",
       " '<extra_id_88>': 39,\n",
       " '<extra_id_87>': 40,\n",
       " '<extra_id_86>': 41,\n",
       " '<extra_id_85>': 42,\n",
       " '<extra_id_84>': 43,\n",
       " '<extra_id_83>': 44,\n",
       " '<extra_id_82>': 45,\n",
       " '<extra_id_81>': 46,\n",
       " '<extra_id_80>': 47,\n",
       " '<extra_id_79>': 48,\n",
       " '<extra_id_78>': 49,\n",
       " '<extra_id_77>': 50,\n",
       " '<extra_id_76>': 51,\n",
       " '<extra_id_75>': 52,\n",
       " '<extra_id_74>': 53,\n",
       " '<extra_id_73>': 54,\n",
       " '<extra_id_72>': 55,\n",
       " '<extra_id_71>': 56,\n",
       " '<extra_id_70>': 57,\n",
       " '<extra_id_69>': 58,\n",
       " '<extra_id_68>': 59,\n",
       " '<extra_id_67>': 60,\n",
       " '<extra_id_66>': 61,\n",
       " '<extra_id_65>': 62,\n",
       " '<extra_id_64>': 63,\n",
       " '<extra_id_63>': 64,\n",
       " '<extra_id_62>': 65,\n",
       " '<extra_id_61>': 66,\n",
       " '<extra_id_60>': 67,\n",
       " '<extra_id_59>': 68,\n",
       " '<extra_id_58>': 69,\n",
       " '<extra_id_57>': 70,\n",
       " '<extra_id_56>': 71,\n",
       " '<extra_id_55>': 72,\n",
       " '<extra_id_54>': 73,\n",
       " '<extra_id_53>': 74,\n",
       " '<extra_id_52>': 75,\n",
       " '<extra_id_51>': 76,\n",
       " '<extra_id_50>': 77,\n",
       " '<extra_id_49>': 78,\n",
       " '<extra_id_48>': 79,\n",
       " '<extra_id_47>': 80,\n",
       " '<extra_id_46>': 81,\n",
       " '<extra_id_45>': 82,\n",
       " '<extra_id_44>': 83,\n",
       " '<extra_id_43>': 84,\n",
       " '<extra_id_42>': 85,\n",
       " '<extra_id_41>': 86,\n",
       " '<extra_id_40>': 87,\n",
       " '<extra_id_39>': 88,\n",
       " '<extra_id_38>': 89,\n",
       " '<extra_id_37>': 90,\n",
       " '<extra_id_36>': 91,\n",
       " '<extra_id_35>': 92,\n",
       " '<extra_id_34>': 93,\n",
       " '<extra_id_33>': 94,\n",
       " '<extra_id_32>': 95,\n",
       " '<extra_id_31>': 96,\n",
       " '<extra_id_30>': 97,\n",
       " '<extra_id_29>': 98,\n",
       " '<extra_id_28>': 99,\n",
       " '<extra_id_27>': 100,\n",
       " '<extra_id_26>': 101,\n",
       " '<extra_id_25>': 102,\n",
       " '<extra_id_24>': 103,\n",
       " '<extra_id_23>': 104,\n",
       " '<extra_id_22>': 105,\n",
       " '<extra_id_21>': 106,\n",
       " '<extra_id_20>': 107,\n",
       " '<extra_id_19>': 108,\n",
       " '<extra_id_18>': 109,\n",
       " '<extra_id_17>': 110,\n",
       " '<extra_id_16>': 111,\n",
       " '<extra_id_15>': 112,\n",
       " '<extra_id_14>': 113,\n",
       " '<extra_id_13>': 114,\n",
       " '<extra_id_12>': 115,\n",
       " '<extra_id_11>': 116,\n",
       " '<extra_id_10>': 117,\n",
       " '<extra_id_9>': 118,\n",
       " '<extra_id_8>': 119,\n",
       " '<extra_id_7>': 120,\n",
       " '<extra_id_6>': 121,\n",
       " '<extra_id_5>': 122,\n",
       " '<extra_id_4>': 123,\n",
       " '<extra_id_3>': 124,\n",
       " '<extra_id_2>': 125,\n",
       " '<extra_id_1>': 126,\n",
       " '<extra_id_0>': 127}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1bacf018",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids = torch.tensor(ids2['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids2['attention_mask']).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embfull    = fullmodel(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=input_ids)\n",
    "    embfull_nh = fullmodel_nohead(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af74cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b3d7b640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3036208152770996"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = fullmodel(input_ids=input_ids, labels=input_ids).loss\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "28169e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = fullmodel.generate(input_ids=input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "252b2352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> P S X T E I N A</s>'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a9f93a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 13, 127,  23,  11,   9,  12,  17,   3,   1]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fd897a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[13, 127, 23, 11, 9, 12, 17, 3, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee687901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
